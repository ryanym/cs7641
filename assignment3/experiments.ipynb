{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer, fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "IMAGE_DIR = 'figures/'  # output images directory\n",
    "\n",
    "\n",
    "def load_dataset(dataset='MADELON', split_percentage=0.2):\n",
    "\n",
    "    datasets = ['MADELON', 'MNIST']  # datasets names\n",
    "    print('\\nLoading {} Dataset'.format(dataset))\n",
    "\n",
    "    if dataset == datasets[0]:\n",
    "\n",
    "        data = fetch_openml('madelon')\n",
    "        x, y = data.data, data.target\n",
    "        x, _, y, _ = train_test_split(x, y, test_size=None, shuffle=True, random_state=42, stratify=y)\n",
    "        labels = ['0', '1']  # labels\n",
    "        y = y.astype(int)\n",
    "\n",
    "    elif dataset == datasets[1]:\n",
    "\n",
    "        data = fetch_openml('mnist_784')\n",
    "        x, y = data.data, data.target\n",
    "        x, _, y, _ = train_test_split(x, y, test_size=0.90, shuffle=True, random_state=42, stratify=y)\n",
    "        labels = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']  # labels\n",
    "        y = y.astype(int)\n",
    "\n",
    "    # Split dataset in training and validation sets, preserving classes representation\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=split_percentage, shuffle=True,\n",
    "                                                        random_state=42, stratify=y)\n",
    "\n",
    "    # Normalize feature data\n",
    "    scaler = StandardScaler()\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "\n",
    "    print('\\nTotal dataset size:')\n",
    "    print('Number of instances: {}'.format(x.shape[0]))\n",
    "    print('Number of features: {}'.format(x.shape[1]))\n",
    "    print('Number of classes: {}'.format(len(labels)))\n",
    "    print('Training Set : {}'.format(x_train.shape))\n",
    "    print('Testing Set : {}'.format(x_test.shape))\n",
    "\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering script\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import utils\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score, completeness_score, \\\n",
    "                            homogeneity_score, v_measure_score, silhouette_samples, silhouette_score\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "\n",
    "class Clustering(ABC):\n",
    "\n",
    "    def __init__(self, name, n_clusters, max_n_clusters, name_param, random_seed):\n",
    "       \n",
    "        self.name = name\n",
    "        self.model = None\n",
    "        self.clusters = None\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_n_clusters = max_n_clusters\n",
    "        self.name_param = name_param\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "    @staticmethod\n",
    "    def benchmark(x, y, clusters):\n",
    "       \n",
    "        print('homo\\tcompl\\tv-meas\\tARI\\tAMI\\tsilhouette')\n",
    "        print('{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}'.format(homogeneity_score(y, clusters),\n",
    "                                                                      completeness_score(y, clusters),\n",
    "                                                                      v_measure_score(y, clusters),\n",
    "                                                                      adjusted_rand_score(y, clusters),\n",
    "                                                                      adjusted_mutual_info_score(y, clusters, average_method='arithmetic'),\n",
    "                                                                      silhouette_score(x, clusters, metric='euclidean')))\n",
    "\n",
    "    def experiment(self, x_train, x_test, y_train, dataset, perform_model_complexity):\n",
    "        \n",
    "        if perform_model_complexity:\n",
    "            self.plot_model_complexity(x_train, y_train, dataset)\n",
    "\n",
    "        self.train(x_train, y_train)  # fit the model and benchmark on training data\n",
    "        self.visualize_clusters(x_train, y_train, dataset)  # visualize clusters with PCA and TSNE\n",
    "\n",
    "        return self.clusters, self.predict(x_test)  # predict on test data and return training and test clusters\n",
    "\n",
    "    @abstractmethod\n",
    "    def plot_model_complexity(self, x, dataset):\n",
    "       \n",
    "        pass\n",
    "\n",
    "    def predict(self, x):\n",
    "\n",
    "        return self.model.predict(x)\n",
    "\n",
    "    def set_n_clusters(self, n_clusters):\n",
    "       \n",
    "        self.n_clusters = n_clusters\n",
    "        self.model.set_params(**{'n_clusters': n_clusters})\n",
    "\n",
    "    def train(self, x, y):\n",
    "       \n",
    "        print('\\nTrain on training set with k={}'.format(self.n_clusters))\n",
    "        self.clusters = self.model.fit_predict(x)\n",
    "        self.benchmark(x, y, self.clusters)\n",
    "\n",
    "    def visualize_clusters(self, x, y, dataset):\n",
    "       \n",
    "\n",
    "        # Declare PCA and reduce data\n",
    "        pca = PCA(n_components=2, random_state=self.random_seed)\n",
    "        x_pca = pca.fit_transform(x)\n",
    "\n",
    "        # Declare TSNE and reduce data\n",
    "        tsne = TSNE(n_components=2, random_state=self.random_seed)\n",
    "        x_tsne = tsne.fit_transform(x)\n",
    "\n",
    "        n_classes = len(np.unique(y))  # compute number of classes\n",
    "        print('\\nBenchmark Model with k = n classes = {}'.format(n_classes))\n",
    "\n",
    "        # Benchamark the model with number of clusters (k) = number of classes\n",
    "        model = clone(self.model)\n",
    "        model_params = self.model.get_params()\n",
    "        model_params[self.name_param] = n_classes\n",
    "        model.set_params(**model_params)\n",
    "        clusters = model.fit_predict(x)\n",
    "        self.benchmark(x, y, clusters)\n",
    "\n",
    "        # Create dataframe for visualization\n",
    "        df = pd.DataFrame(x_tsne, columns=['tsne1', 'tsne2'])\n",
    "        df['pca1'] = x_pca[:, 0]\n",
    "        df['pca2'] = x_pca[:, 1]\n",
    "        df['y'] = y\n",
    "        df['c'] = self.clusters\n",
    "\n",
    "        # Create subplot and plot clusters with PCA and TSNE\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 2, figsize=(15, 8))\n",
    "        utils.plot_clusters(ax1, 'pca1', 'pca2', df, self.name)\n",
    "        utils.plot_clusters(ax2, 'tsne1', 'tsne2', df, self.name)\n",
    "\n",
    "        # Save figure\n",
    "        utils.save_figure_tight('{}_{}_clusters'.format(dataset, self.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeansClustering(Clustering):\n",
    "\n",
    "    def __init__(self,  n_clusters=2, max_n_clusters=10, random_seed=42):\n",
    "    \n",
    "        super(KMeansClustering, self).__init__(name='k-means', n_clusters=n_clusters, max_n_clusters=max_n_clusters,\n",
    "                                               name_param='n_clusters', random_seed=random_seed)\n",
    "        self.model = KMeans(n_clusters=n_clusters, init='k-means++', max_iter=1000, random_state=random_seed, n_jobs=-1)\n",
    "\n",
    "    def plot_model_complexity(self, x, y, dataset):\n",
    "      \n",
    "        print('\\nPlot Model Complexity')\n",
    "\n",
    "        inertia, inertia_diff = [], []  # inertia and delta inertia\n",
    "        if \"MADELON\" in dataset:\n",
    "            k_range = np.arange(2, self.max_n_clusters + 1)  # range of number of clusters k to plot over\n",
    "        elif \"MNIST\" in dataset:\n",
    "            k_range = [1, 2, 5, 8, 10, 12, 15, 20]\n",
    "        homogeneity = []\n",
    "        completeness = []\n",
    "        silhouette = []\n",
    "        # For each k in the range\n",
    "        for k in k_range:\n",
    "\n",
    "            # Define a new k-Means model, fit on training data and report inertia\n",
    "            model = KMeans(n_clusters=k, init='k-means++', max_iter=1000, random_state=self.random_seed, n_jobs=-1)\n",
    "            clusters = model.fit_predict(x)\n",
    "            inertia.append(model.inertia_)\n",
    "            h_score = homogeneity_score(y, clusters)\n",
    "            if k != 1:\n",
    "                s_score = silhouette_score(x, clusters, metric='euclidean')\n",
    "            else:\n",
    "                s_score = 0\n",
    "            c_score = completeness_score(y, clusters)\n",
    "            homogeneity.append(h_score)\n",
    "            silhouette.append(s_score)\n",
    "            completeness.append(c_score)\n",
    "            print('k = {} -->  inertia = {:.3f}  silhouette = {:.3f} homogeneity = {:.3f} completeness = {:.3f}'.format(k,\n",
    "                                                                                                 inertia[-1],\n",
    "                                                                                                 h_score,\n",
    "                                                                                                 s_score,\n",
    "                                                                                                 c_score,\n",
    "                                                                                                 ))\n",
    "\n",
    "\n",
    "        # Create subplots and plot inertia and delta inertia on the first suplot\n",
    "        fig, ax = plt.subplots(1, 4, figsize=(16, 4))\n",
    "        ax = ax.flatten()\n",
    "        ax[0].plot(k_range, inertia, '-o', markersize=2, label='Inertia')\n",
    "\n",
    "        # Set legend, title and labels\n",
    "        utils.set_axis_title_labels(ax[0], title='K-Means - Inertia',\n",
    "                                    x_label='Number of clusters k', y_label='Inertia')\n",
    "\n",
    "        ax[1].plot(k_range[1:], silhouette[1:], '-o', markersize=2, label='Silhouette')\n",
    "        utils.set_axis_title_labels(ax[2], title='K-Means - Silhouette Score',\n",
    "                                    x_label='Number of clusters k', y_label='Silhouette')\n",
    "        ax[2].plot(k_range, homogeneity, '-o', markersize=2, label='Homogeneity')\n",
    "        utils.set_axis_title_labels(ax[1], title='K-Means - Homogeneity Score',\n",
    "                                    x_label='Number of clusters k', y_label='Homogeneity')\n",
    "        ax[3].plot(k_range, completeness, '-o', markersize=2, label='Completeness')\n",
    "        utils.set_axis_title_labels(ax[3], title='K-Means - Completeness Score',\n",
    "                                    x_label='Number of clusters k', y_label='Completeness')\n",
    "        # Save figure\n",
    "        utils.save_figure_tight('{}_{}_model_complexity'.format(dataset, self.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectation Maximization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MixtureOfGaussians(Clustering):\n",
    "    \n",
    "    def __init__(self, n_clusters=2, covariance='full', max_n_clusters=10, random_seed=42):\n",
    "        \n",
    "        super(MixtureOfGaussians, self).__init__(name='em', n_clusters=n_clusters, max_n_clusters=max_n_clusters,\n",
    "                                                 name_param='n_components', random_seed=random_seed)\n",
    "        self.model = GaussianMixture(n_components=n_clusters, covariance_type=covariance, max_iter=1000,\n",
    "                                     n_init=10, init_params='random', random_state=random_seed)\n",
    "\n",
    "    def plot_model_complexity(self, x, y, dataset):\n",
    "        \n",
    "\n",
    "        print('\\nPlot Model Complexity')\n",
    "        if \"MADELON\" in dataset:\n",
    "            k_range = np.arange(2, self.max_n_clusters + 1)  # range of number of clusters k to plot over\n",
    "        elif \"MNIST\" in dataset:\n",
    "            k_range = [1, 2, 5, 8, 10, 12, 15, 20]\n",
    "        # cv_types = ['spherical', 'tied', 'diag', 'full']  # covariance types to plot over\n",
    "        cv_types = ['diag']  # covariance types to plot over\n",
    "        fig, ax = plt.subplots(1, 4, figsize=(16, 4))\n",
    "        homogeneity = []\n",
    "        completeness = []\n",
    "        # For all pair covariance, number of clusters k\n",
    "        for cv_type in cv_types:\n",
    "            aic, bic = [], []  # AIC and BIC  scores lists\n",
    "            for k in k_range:\n",
    "\n",
    "                # Define a new Gaussian Mixture model, fit on training data and report AIC and BIC\n",
    "                gmm = GaussianMixture(n_components=k, covariance_type=cv_type, max_iter=1000,\n",
    "                                      n_init=10, init_params='random', random_state=self.random_seed)\n",
    "                clusters = gmm.fit_predict(x)\n",
    "                aic.append(gmm.aic(x))\n",
    "                bic.append(gmm.bic(x))\n",
    "\n",
    "                print('cv = {}, k = {} --> aic = {:.3f}, bic = {:.3f}'.format(cv_type, k, aic[-1], bic[-1]))\n",
    "                if cv_type == 'diag':\n",
    "                    h_score = homogeneity_score(y, clusters)\n",
    "                    c_score = completeness_score(y, clusters)\n",
    "                    homogeneity.append(h_score)\n",
    "                    completeness.append(c_score)\n",
    "                    print('cv_type = {}, k = {} --> homogeneity = {:.3f}, completeness = {:.3f}'.format(cv_type, k,\n",
    "                                                                                                        h_score,\n",
    "                                                                                                        c_score))\n",
    "\n",
    "            ax[0].plot(k_range, aic, '-o', label=cv_type)\n",
    "            ax[1].plot(k_range, bic, '-o', label=cv_type)\n",
    "\n",
    "        for i in range(4):\n",
    "            ax[i].set_xticks(k_range)\n",
    "\n",
    "        ax[0].legend(loc='best')\n",
    "        ax[1].legend(loc='best')\n",
    "\n",
    "        utils.set_axis_title_labels(ax[0], title='EM - AIC Score',\n",
    "                                    x_label='Number of clusters k', y_label='AIC')\n",
    "        utils.set_axis_title_labels(ax[1], title='EM - BIC Score',\n",
    "                                    x_label='Number of clusters k', y_label='BIC')\n",
    "\n",
    "        ax[2].plot(k_range, homogeneity, '-o', markersize=2, label='Homogeneity')\n",
    "        utils.set_axis_title_labels(ax[2], title='EM - Homogeneity Score',\n",
    "                                    x_label='Number of clusters k', y_label='Homogeneity')\n",
    "        ax[3].plot(k_range, completeness, '-o', markersize=2, label='Completeness')\n",
    "        utils.set_axis_title_labels(ax[3], title='EM - Completeness Score',\n",
    "                                    x_label='Number of clusters k', y_label='Completeness')\n",
    "        # Save figure\n",
    "        utils.save_figure_tight('{}_{}_model_complexity'.format(dataset, self.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Running Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def clustering(x_train, x_test, y_train, **kwargs):\n",
    "    print('\\n--------------------------')\n",
    "    print('kMeans')\n",
    "\n",
    "    # # Declare kMeans, perform experiments and get clusters on training data\n",
    "    kmeans = KMeansClustering(n_clusters=kwargs['kmeans_n_clusters'], max_n_clusters=10)\n",
    "    kmeans_clusters = kmeans.experiment(x_train, x_test, y_train,\n",
    "                                        dataset=kwargs['dataset'],\n",
    "                                        perform_model_complexity=kwargs['perform_model_complexity'])\n",
    "\n",
    "    print('\\n--------------------------')\n",
    "    print('GMM')\n",
    "\n",
    "    # Declare Gaussian Mixtures Models, perform experiments and get clusters on training data\n",
    "    gmm = MixtureOfGaussians(n_clusters=kwargs['em_n_clusters'], covariance=kwargs['em_covariance'], max_n_clusters=10)\n",
    "    gmm_clusters = gmm.experiment(x_train, x_test, y_train,\n",
    "                                  dataset=kwargs['dataset'],\n",
    "                                  perform_model_complexity=kwargs['perform_model_complexity'])\n",
    "\n",
    "    return kmeans_clusters, gmm_clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading MNIST Dataset\n",
      "\n",
      "Total dataset size:\n",
      "Number of instances: 7000\n",
      "Number of features: 784\n",
      "Number of classes: 10\n",
      "Training Set : (5600, 784)\n",
      "Testing Set : (1400, 784)\n",
      "\n",
      "--------------------------\n",
      "kMeans\n",
      "\n",
      "Plot Model Complexity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1 -->  inertia = 3724000.000  silhouette = 0.000 homogeneity = 0.000 completeness = 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 2 -->  inertia = 3571445.749  silhouette = 0.085 homogeneity = 0.128 completeness = 0.323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 5 -->  inertia = 3324480.165  silhouette = 0.273 homogeneity = 0.005 completeness = 0.413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 8 -->  inertia = 3169614.326  silhouette = 0.382 homogeneity = -0.002 completeness = 0.440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 10 -->  inertia = 3096530.915  silhouette = 0.421 homogeneity = 0.005 completeness = 0.446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 12 -->  inertia = 3031015.351  silhouette = 0.460 homogeneity = 0.003 completeness = 0.455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 15 -->  inertia = 2956470.050  silhouette = 0.476 homogeneity = -0.006 completeness = 0.429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 20 -->  inertia = 2853873.608  silhouette = 0.530 homogeneity = -0.008 completeness = 0.442\n",
      "\n",
      "Train on training set with k=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "0.339\t0.455\t0.389\t0.269\t0.387\t-0.003\n",
      "\n",
      "Benchmark Model with k = n classes = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "0.421\t0.446\t0.433\t0.319\t0.432\t0.005\n",
      "\n",
      "--------------------------\n",
      "GMM\n",
      "\n",
      "Plot Model Complexity\n",
      "cv = diag, k = 1 --> aic = 2589495.237, bic = 2599891.895\n",
      "cv_type = diag, k = 1 --> homogeneity = 0.000, completeness = 1.000\n",
      "cv = diag, k = 2 --> aic = -5470985.602, bic = -5450185.655\n",
      "cv_type = diag, k = 2 --> homogeneity = 0.016, completeness = 0.094\n",
      "cv = diag, k = 5 --> aic = -12918684.505, bic = -12866674.691\n",
      "cv_type = diag, k = 5 --> homogeneity = 0.077, completeness = 0.153\n",
      "cv = diag, k = 8 --> aic = -15374107.457, bic = -15290887.777\n",
      "cv_type = diag, k = 8 --> homogeneity = 0.172, completeness = 0.243\n",
      "cv = diag, k = 10 --> aic = -16130289.523, bic = -16026263.266\n",
      "cv_type = diag, k = 10 --> homogeneity = 0.200, completeness = 0.236\n",
      "cv = diag, k = 12 --> aic = -18364011.512, bic = -18239178.677\n",
      "cv_type = diag, k = 12 --> homogeneity = 0.183, completeness = 0.220\n",
      "cv = diag, k = 15 --> aic = -18361012.956, bic = -18204970.255\n",
      "cv_type = diag, k = 15 --> homogeneity = 0.190, completeness = 0.204\n",
      "cv = diag, k = 20 --> aic = -19973719.817, bic = -19765660.671\n",
      "cv_type = diag, k = 20 --> homogeneity = 0.274, completeness = 0.252\n",
      "\n",
      "Train on training set with k=10\n",
      "homo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "0.041\t0.049\t0.045\t0.037\t0.042\t-0.034\n",
      "\n",
      "Benchmark Model with k = n classes = 10\n",
      "homo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "0.041\t0.049\t0.045\t0.037\t0.042\t-0.034\n"
     ]
    }
   ],
   "source": [
    "dataset = 'MNIST'\n",
    "x_train, x_test, y_train, y_test = load_dataset(dataset)\n",
    "kmeans_clusters, gmm_clusters = clustering(x_train, x_test, y_train,\n",
    "                                                   dataset=dataset,\n",
    "                                                   kmeans_n_clusters=6,\n",
    "                                                   em_n_clusters=10, em_covariance='full',\n",
    "                                                   perform_model_complexity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading MADELON Dataset\n",
      "\n",
      "Total dataset size:\n",
      "Number of instances: 1950\n",
      "Number of features: 500\n",
      "Number of classes: 2\n",
      "Training Set : (1560, 500)\n",
      "Testing Set : (390, 500)\n",
      "\n",
      "--------------------------\n",
      "kMeans\n",
      "\n",
      "Plot Model Complexity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 2 -->  inertia = 772874.876  silhouette = 0.015 homogeneity = 0.008 completeness = 0.015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 3 -->  inertia = 768996.931  silhouette = 0.033 homogeneity = 0.006 completeness = 0.021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 4 -->  inertia = 765973.644  silhouette = 0.004 homogeneity = 0.006 completeness = 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 5 -->  inertia = 764083.611  silhouette = 0.005 homogeneity = 0.005 completeness = 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 6 -->  inertia = 762440.747  silhouette = 0.031 homogeneity = 0.005 completeness = 0.012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 7 -->  inertia = 761375.590  silhouette = 0.040 homogeneity = 0.004 completeness = 0.014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 8 -->  inertia = 760659.948  silhouette = 0.031 homogeneity = 0.004 completeness = 0.011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 9 -->  inertia = 759514.670  silhouette = 0.022 homogeneity = 0.003 completeness = 0.007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 10 -->  inertia = 759005.094  silhouette = 0.016 homogeneity = 0.003 completeness = 0.005\n",
      "\n",
      "Train on training set with k=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "0.031\t0.012\t0.017\t0.012\t0.016\t0.005\n",
      "\n",
      "Benchmark Model with k = n classes = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "0.015\t0.015\t0.015\t0.020\t0.014\t0.008\n",
      "\n",
      "--------------------------\n",
      "GMM\n",
      "\n",
      "Plot Model Complexity\n",
      "cv = diag, k = 2 --> aic = 2209415.225, bic = 2220125.459\n",
      "cv_type = diag, k = 2 --> homogeneity = 0.000, completeness = 0.000\n",
      "cv = diag, k = 3 --> aic = 2206237.718, bic = 2222305.746\n",
      "cv_type = diag, k = 3 --> homogeneity = 0.006, completeness = 0.004\n",
      "cv = diag, k = 4 --> aic = 2204232.959, bic = 2225658.780\n",
      "cv_type = diag, k = 4 --> homogeneity = 0.003, completeness = 0.002\n",
      "cv = diag, k = 5 --> aic = 2202381.375, bic = 2229164.990\n",
      "cv_type = diag, k = 5 --> homogeneity = 0.007, completeness = 0.003\n",
      "cv = diag, k = 6 --> aic = 2201613.167, bic = 2233754.576\n",
      "cv_type = diag, k = 6 --> homogeneity = 0.012, completeness = 0.005\n",
      "cv = diag, k = 7 --> aic = 2200764.617, bic = 2238263.819\n",
      "cv_type = diag, k = 7 --> homogeneity = 0.021, completeness = 0.007\n",
      "cv = diag, k = 8 --> aic = 2200933.652, bic = 2243790.648\n",
      "cv_type = diag, k = 8 --> homogeneity = 0.032, completeness = 0.011\n",
      "cv = diag, k = 9 --> aic = 2200472.556, bic = 2248687.345\n",
      "cv_type = diag, k = 9 --> homogeneity = 0.097, completeness = 0.031\n",
      "cv = diag, k = 10 --> aic = 2201620.672, bic = 2255193.255\n",
      "cv_type = diag, k = 10 --> homogeneity = 0.051, completeness = 0.016\n",
      "\n",
      "Train on training set with k=10\n",
      "homo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "0.009\t0.003\t0.004\t0.001\t0.002\t-0.003\n",
      "\n",
      "Benchmark Model with k = n classes = 2\n",
      "homo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "0.000\t0.000\t0.000\t-0.000\t-0.000\t0.000\n"
     ]
    }
   ],
   "source": [
    "dataset = 'MADELON'\n",
    "x_train, x_test, y_train, y_test = load_dataset(dataset)\n",
    "kmeans_clusters, gmm_clusters = clustering(x_train, x_test, y_train,\n",
    "                                                   dataset=dataset,\n",
    "                                                   kmeans_n_clusters=6,\n",
    "                                                   em_n_clusters=10, em_covariance='full',\n",
    "                                                   perform_model_complexity=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import kurtosis\n",
    "from sklearn.decomposition import FastICA, KernelPCA, PCA\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "\n",
    "class DimensionalityReduction(ABC):\n",
    "\n",
    "    def __init__(self, name, n_components, random_seed):\n",
    "        self.name = name\n",
    "        self.model = None\n",
    "        self.n_components = n_components\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "    def experiment(self, x_train, x_test, y_train, dataset, perform_model_complexity):\n",
    "        print('\\nTrain on training set')\n",
    "\n",
    "        if perform_model_complexity:\n",
    "            self.plot_model_complexity(x_train, dataset)\n",
    "\n",
    "        x_train_reduced, mse = self.train(x_train)  # fit and reduce training data\n",
    "        print('Reconstruction error = {:.3f}'.format(mse))\n",
    "        self.visualize_components(x_train_reduced, y_train, dataset)  # visualize components\n",
    "        print('Reduced dimension: ', x_train_reduced.shape)\n",
    "        return x_train_reduced,  self.reduce(x_test)  # reduce test data and return reduced training and test data\n",
    "\n",
    "    @abstractmethod\n",
    "    def plot_model_complexity(self, x, dataset, y_train=None):\n",
    "\n",
    "        pass\n",
    "\n",
    "    def reconstruct(self, x, x_reduced):\n",
    "\n",
    "        x_reconstructed = self.model.inverse_transform(x_reduced)  # reconstruct\n",
    "        mse = np.mean((x - x_reconstructed) ** 2)  # compute MSE\n",
    "        return mse\n",
    "\n",
    "    def reduce(self, x):\n",
    "\n",
    "        return self.model.transform(x)\n",
    "\n",
    "    def set_n_components(self, n_components):\n",
    "\n",
    "        self.n_components = n_components\n",
    "        self.model.set_params(**{'n_components': n_components})\n",
    "\n",
    "    def train(self, x):\n",
    "\n",
    "        x_reduced = self.model.fit_transform(x)  # fit model\n",
    "        mse = self.reconstruct(x, x_reduced)  # reconstruct and compute MSE\n",
    "        return x_reduced, mse\n",
    "\n",
    "    def visualize_components(self, x_reduced, y, dataset):\n",
    "\n",
    "        component1 = '{}1'.format(self.name)  # first component\n",
    "        component2 = '{}2'.format(self.name)  # second component\n",
    "\n",
    "        # Create dataframe for visualization\n",
    "        df = pd.DataFrame(x_reduced[:, :2], columns=[component1, component2])\n",
    "        df['y'] = y\n",
    "\n",
    "        # Plot components and save figure\n",
    "        utils.plot_components(component1, component2, df, self.name)\n",
    "        utils.save_figure('{}_{}_components'.format(dataset, self.name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class PrincipalComponents(DimensionalityReduction):\n",
    "\n",
    "    def __init__(self, n_components=2, random_seed=42):\n",
    "\n",
    "        super(PrincipalComponents, self).__init__(name='pca', n_components=n_components, random_seed=random_seed)\n",
    "        self.model = PCA(n_components=n_components, svd_solver='randomized', random_state=random_seed)\n",
    "\n",
    "    def plot_model_complexity(self, x, dataset):\n",
    "\n",
    "\n",
    "        print('\\nPlot Model Complexity')\n",
    "\n",
    "        k_range = np.arange(1, x.shape[1]+1)  # range of number of components k to plot over\n",
    "\n",
    "        # Create PCA object and fit it on training data\n",
    "        pca = PCA(svd_solver='randomized', random_state=self.random_seed)\n",
    "        pca.fit(x)\n",
    "\n",
    "        # Compute the total explained variance given by the chosen number of components\n",
    "        explained_variance = np.sum(pca.explained_variance_ratio_[:self.n_components])\n",
    "        print('Explained variance [n components = {}]= {:.3f}'.format(self.n_components, explained_variance))\n",
    "\n",
    "        # Create subplots\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 5))\n",
    "\n",
    "        if \"MADELON\" in dataset:\n",
    "            ax1.plot(k_range, pca.explained_variance_ratio_, color='green')\n",
    "            utils.set_axis_title_labels(ax1, title='MADELON - PCA - Eigenvalues distributions',\n",
    "                                        x_label='Number of components k', y_label='Variance (%)')\n",
    "\n",
    "            ax2.plot(k_range, np.cumsum(pca.explained_variance_ratio_), color='b')\n",
    "            utils.set_axis_title_labels(ax2, title='MADELON - PCA - Choosing k with the Variance method',\n",
    "                                        x_label='Number of components k', y_label='Cumulative Variance (%)')\n",
    "\n",
    "        else:\n",
    "            ax1.plot(k_range, pca.explained_variance_ratio_, color='green')\n",
    "            utils.set_axis_title_labels(ax1, title='MNIST - PCA - Eigenvalues distributions',\n",
    "                                        x_label='Number of components k', y_label='Variance (%)')\n",
    "\n",
    "            ax2.plot(k_range, np.cumsum(pca.explained_variance_ratio_), color='b')\n",
    "            utils.set_axis_title_labels(ax2, title='MNIST - PCA - Choosing k with the Variance method',\n",
    "                                        x_label='Number of components k', y_label='Cumulative Variance (%)')\n",
    "\n",
    "        # Save figure\n",
    "        utils.save_figure_tight('{}_pca_model_complexity'.format(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class IndependentComponents(DimensionalityReduction):\n",
    "\n",
    "    def __init__(self, n_components=2, random_seed=42):\n",
    "\n",
    "        super(IndependentComponents, self).__init__(name='ica', n_components=n_components, random_seed=random_seed)\n",
    "        self.model = FastICA(n_components=n_components, tol=0.05, max_iter=2000, random_state=random_seed)\n",
    "\n",
    "    def plot_model_complexity(self, x, dataset):\n",
    "\n",
    "\n",
    "        print('\\nPlot Model Complexity')\n",
    "\n",
    "        average_kurtosis = []  # list of average kurtosis\n",
    "\n",
    "        # Define range of number of components k to plot over\n",
    "        if x.shape[1] < 100:\n",
    "            k_range = np.arange(1, x.shape[1] + 1)\n",
    "        else:\n",
    "            k_range = np.arange(0, int(0.8 * x.shape[1]) + 1, 20)\n",
    "            k_range[0] = 1\n",
    "\n",
    "        # For each k in the range\n",
    "        for k in k_range:\n",
    "\n",
    "            # Define a new ICA model and fit on training data\n",
    "            ica = FastICA(n_components=k, tol=0.05, max_iter=20000, random_state=self.random_seed)\n",
    "            ica.fit(x)\n",
    "\n",
    "            # Compute kurtosis of components and report the average\n",
    "            components_kurtosis = kurtosis(ica.components_, axis=1, fisher=False)\n",
    "            average_kurtosis.append(np.mean(components_kurtosis))\n",
    "            print('k = {} --> average kurtosis = {:.3f}'.format(k, average_kurtosis[-1]))\n",
    "\n",
    "        # Create subplots and plot average kurtosis on the first suplot\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 5))\n",
    "        ax1.plot(k_range, average_kurtosis,  '-o', markersize=1, label='Kurtosis')\n",
    "\n",
    "        # Set title and labels\n",
    "        utils.set_axis_title_labels(ax1, title='ICA - Choosing k with the Average Kurtosis method',\n",
    "                                    x_label='Number of components k', y_label='Average Kurtosis')\n",
    "\n",
    "        # Fit our ICA model on training data\n",
    "        self.model.fit(x)\n",
    "\n",
    "        # Define x values to show on plot\n",
    "        if x.shape[1] < 100:\n",
    "            x_ticks = np.arange(1, self.n_components + 1)\n",
    "        else:\n",
    "            x_ticks = np.arange(0, self.n_components + 1, 50)\n",
    "            x_ticks[0] = 1\n",
    "\n",
    "        # Compute kurtosis of components\n",
    "        components_kurtosis = kurtosis(self.model.components_, axis=1, fisher=False)\n",
    "\n",
    "        # Plot kurtosis distribution\n",
    "        ax2.bar(np.arange(1, self.n_components + 1), components_kurtosis, color='g')\n",
    "\n",
    "        # Set title, labels and x values to show on plot\n",
    "        ax2.set_xticks(x_ticks)\n",
    "        utils.set_axis_title_labels(ax2, title='ICA - Components Kurtosis Distribution',\n",
    "                                    x_label='Independent component', y_label='Kurtosis')\n",
    "\n",
    "        # Save figure\n",
    "        utils.save_figure_tight('{}_ica_model_complexity'.format(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class RandomProjections(DimensionalityReduction):\n",
    "\n",
    "    def __init__(self, n_components=2, random_runs=100, random_seed=42):\n",
    "\n",
    "        super(RandomProjections, self).__init__(name='rp', n_components=n_components, random_seed=random_seed)\n",
    "        self.model = SparseRandomProjection(n_components=n_components, random_state=random_seed)\n",
    "        self.random_runs = random_runs\n",
    "\n",
    "    def experiment(self, x_train, x_test, y_train, dataset, perform_model_complexity):\n",
    "\n",
    "\n",
    "        print('\\nTrain on training set')\n",
    "\n",
    "        if perform_model_complexity:\n",
    "            self.plot_model_complexity(x_train, dataset)\n",
    "\n",
    "        # Initialize training errors, reduced training and test data\n",
    "        train_errors = []\n",
    "        x_train_reduced = np.zeros((x_train.shape[0], self.n_components))\n",
    "        x_test_reduced = np.zeros((x_test.shape[0], self.n_components))\n",
    "\n",
    "        # Perform the defined number of random restarts\n",
    "        for seed in range(self.random_seed, self.random_seed + self.random_runs):\n",
    "\n",
    "            # Define new sparse RP model\n",
    "            self.model = SparseRandomProjection(n_components=self.n_components, random_state=seed)\n",
    "\n",
    "            # Train on training data\n",
    "            x_reduced, mse = self.train(x_train)\n",
    "\n",
    "            # Account for reduced training data and MSE for current run\n",
    "            x_train_reduced += x_reduced\n",
    "            train_errors.append(mse)\n",
    "\n",
    "            # Account for reduced test data\n",
    "            x_reduced = self.reduce(x_test)\n",
    "            x_test_reduced += x_reduced\n",
    "\n",
    "        print('Reconstruction error = {:.3f} with std = {:.3f}'.format(np.mean(train_errors), np.std(train_errors)))\n",
    "\n",
    "        # Normalize the mean reduced training data and test data\n",
    "        x_train_reduced /= self.random_runs\n",
    "        x_test_reduced /= self.random_runs\n",
    "\n",
    "        # Visualize components\n",
    "        self.visualize_components(x_train_reduced, y_train, dataset)\n",
    "\n",
    "        return x_train_reduced, x_test_reduced\n",
    "\n",
    "    def plot_model_complexity(self, x, dataset):\n",
    "\n",
    "        print('\\nPlot Model Complexity')\n",
    "\n",
    "        mse_random_runs = []  # list of MSE over random runs\n",
    "\n",
    "        # Define range of number of components k to plot over\n",
    "        if x.shape[1] < 100:\n",
    "            k_range = np.arange(1, x.shape[1] + 1)\n",
    "        else:\n",
    "            k_range = np.arange(0, int(0.9 * x.shape[1]) + 1, 20)\n",
    "            k_range[0] = 1\n",
    "\n",
    "        # Perform the defined number of random restarts\n",
    "        for seed in range(self.random_seed, self.random_seed + self.random_runs):\n",
    "\n",
    "            print('Random run {}'.format(seed + 1 - self.random_seed))\n",
    "            mse = []  # initialize list of MSE over number of components\n",
    "\n",
    "            # For each k in the range\n",
    "            for k in k_range:\n",
    "\n",
    "                # Define new sparse RP model and reduce training data\n",
    "                rp = SparseRandomProjection(n_components=k, random_state=np.random.randint(1000))\n",
    "                x_reduced = rp.fit_transform(x)\n",
    "\n",
    "                # Compute Pseudo inverse, reconstruct data and compute MSE\n",
    "                P_inv = np.linalg.pinv(rp.components_.toarray())  # dimensions check : k x m -> m x k\n",
    "                x_reconstructed = (P_inv @ x_reduced.T).T  # dimensions check: m x k x k x n = m x n -> n x m\n",
    "                mse.append(np.mean((x - x_reconstructed) ** 2))\n",
    "\n",
    "            mse_random_runs.append(mse)  # append list of MSE over number of components per current random run\n",
    "\n",
    "        np.set_printoptions(precision=2)\n",
    "        print('k = [2, ..., {}] --> \\nReconstruction errors = {}'.format(k_range[-1], np.mean(mse_random_runs, axis=0)))\n",
    "\n",
    "        # Create figure, plot multiple runs and set tile and labels\n",
    "        plt.figure()\n",
    "        utils.plot_multiple_random_runs(k_range, mse_random_runs, 'MSE')\n",
    "        utils.set_plot_title_labels(title='RP - Choosing k with the Reconstruction Error',\n",
    "                                    x_label='Number of components k', y_label='MSE')\n",
    "\n",
    "        # Save figure\n",
    "        utils.save_figure('{}_rp_model_complexity'.format(dataset))\n",
    "\n",
    "    def reconstruct(self, x, x_reduced):\n",
    "\n",
    "        # Compute Pseudo inverse, reconstruct data and compute MSE\n",
    "        P_inv = np.linalg.pinv(self.model.components_.toarray())  # dimensions check : k x m -> m x k\n",
    "        x_reconstructed = (P_inv @ x_reduced.T).T  # dimensions check: m x k x k x n = m x n -> n x m\n",
    "        mse = np.mean((x - x_reconstructed) ** 2)\n",
    "        return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class KernelPrincipalComponents(DimensionalityReduction):\n",
    "\n",
    "    def __init__(self, n_components=2, kernel='rbf', random_seed=42):\n",
    "\n",
    "        super(KernelPrincipalComponents, self).__init__(name='kpca', n_components=n_components, random_seed=random_seed)\n",
    "        self.model = KernelPCA(n_components=n_components, kernel=kernel, fit_inverse_transform=True,\n",
    "                               random_state=random_seed, n_jobs=-1)\n",
    "        self.kernel = kernel\n",
    "\n",
    "    def plot_model_complexity(self, x, dataset):\n",
    "\n",
    "        print('\\nPlot Model Complexity')\n",
    "\n",
    "        k_range = np.arange(1, x.shape[1] + 1)  # range of number of components k to plot over\n",
    "        if \"MADELON\" in dataset:\n",
    "            kernels = ['rbf', 'cosine']  # kernels to plot with\n",
    "        else:\n",
    "            kernels = ['rbf', 'poly', 'sigmoid', 'cosine']  # kernels to plot with\n",
    "\n",
    "        # Create subplots\n",
    "        fig, ax = plt.subplots(2, 4, figsize=(15, 10))\n",
    "        ax = ax.ravel()\n",
    "\n",
    "        # For each kernel\n",
    "        for i, kernel in enumerate(kernels):\n",
    "\n",
    "            # Create KPCA object and fit it on training data\n",
    "            kpca = KernelPCA(n_components=x.shape[1], kernel=kernel, random_state=self.random_seed, n_jobs=-1)\n",
    "            kpca.fit(x)\n",
    "\n",
    "            # Compute explained variance ratio from eigenvalues and the total explained variance\n",
    "            # given by the chosen number of components\n",
    "            explained_variance_ratio = kpca.lambdas_ / np.sum(kpca.lambdas_)\n",
    "            explained_variance = np.sum(explained_variance_ratio[:self.n_components])\n",
    "            print('Kernel = {} - Explained variance [n components = {}]= {:.3f}'.format(kernel,\n",
    "                                                                                        self.n_components,\n",
    "                                                                                        explained_variance))\n",
    "\n",
    "            # Plot histogram of the cumulative explained variance ratio\n",
    "            ax[2*i].plot(k_range, np.cumsum(explained_variance_ratio), color='blue', label=kernel)\n",
    "\n",
    "            # Set title, labels and legend\n",
    "            ax[2*i].legend(loc='best')\n",
    "            utils.set_axis_title_labels(ax[2*i], title='KPCA - Choosing k with the Variance method',\n",
    "                                        x_label='Number of components k', y_label='Cumulative Variance (%)')\n",
    "\n",
    "            # Plot histogram of the explained variance ratio, i.e. the eignevalues distribution\n",
    "            ax[2*i+1].plot(k_range, explained_variance_ratio, color='green', label=kernel)\n",
    "\n",
    "            # Set title, labels and legend\n",
    "            ax[2*i+1].legend(loc='best')\n",
    "            utils.set_axis_title_labels(ax[2*i+1], title='KPCA - Eigenvalues distributions',\n",
    "                                        x_label='Number of components k', y_label='Variance (%)')\n",
    "\n",
    "        # Save figure\n",
    "        utils.save_figure_tight('{}_kpca_model_complexity'.format(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class LinearDiscriminantAnalysis(DimensionalityReduction):\n",
    "    def __init__(self, n_components=10, random_seed=42):\n",
    "\n",
    "        super(LinearDiscriminantAnalysis, self).__init__(name='lda', n_components=n_components, random_seed=random_seed)\n",
    "        self.model = LDA(n_components=n_components)\n",
    "\n",
    "    def experiment(self, x_train, x_test, y_train, dataset, perform_model_complexity):\n",
    "        print('\\nTrain on training set')\n",
    "\n",
    "        if perform_model_complexity:\n",
    "            self.plot_model_complexity(x_train, dataset, y_train)\n",
    "\n",
    "        x_reduced = self.model.fit_transform(x_train, y_train)  # fit model\n",
    "        mse = self.reconstruct(x_train, x_reduced)  # reconstruct and compute MSE\n",
    "        # fit and reduce training data\n",
    "        print('Reconstruction error = {:.3f}'.format(mse))\n",
    "        # self.visualize_components(x_train_reduced, y_train, dataset)  # visualize components\n",
    "        print('Reduced dimension: ', x_reduced.shape)\n",
    "\n",
    "\n",
    "    def plot_model_complexity(self, x, dataset, y=None):\n",
    "\n",
    "        print('\\nPlot Model Complexity')\n",
    "\n",
    "        explained_variance = []  # list of average kurtosis\n",
    "\n",
    "        # Define range of number of components k to plot over\n",
    "        if x.shape[1] < 100:\n",
    "            k_range = np.arange(1, x.shape[1] + 1)\n",
    "        else:\n",
    "            k_range = np.arange(0, int(0.8 * x.shape[1]) + 1, 20)\n",
    "            k_range[0] = 1\n",
    "\n",
    "        for n in range(1,  10):\n",
    "\n",
    "            lda = LDA(n_components=n, tol=0.01)\n",
    "            lda.fit(x, y)\n",
    "            print(lda.explained_variance_ratio_)\n",
    "        # Compute the total explained variance given by the chosen number of components\n",
    "        explained_variance = np.sum(lda.explained_variance_ratio_[:self.n_components])\n",
    "        print('Explained variance [n components = {}]= {:.3f}'.format(self.n_components, explained_variance))\n",
    "\n",
    "        # Create subplots\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 5))\n",
    "\n",
    "        if \"MADELON\" in dataset:\n",
    "            ax1.plot(k_range, lda.explained_variance_ratio_, color='green')\n",
    "            utils.set_axis_title_labels(ax1, title='MADELON - PCA - Eigenvalues distributions',\n",
    "                                        x_label='Number of components k', y_label='Variance (%)')\n",
    "\n",
    "            ax2.plot(k_range, np.cumsum(lda.explained_variance_ratio_), color='b')\n",
    "            utils.set_axis_title_labels(ax2, title='MADELON - PCA - Choosing k with the Variance method',\n",
    "                                        x_label='Number of components k', y_label='Cumulative Variance (%)')\n",
    "\n",
    "        else:\n",
    "            ax1.plot(k_range, lda.explained_variance_ratio_, color='green')\n",
    "            utils.set_axis_title_labels(ax1, title='MNIST - PCA - Eigenvalues distributions',\n",
    "                                        x_label='Number of components k', y_label='Variance (%)')\n",
    "\n",
    "            ax2.plot(k_range, np.cumsum(lda.explained_variance_ratio_), color='b')\n",
    "            utils.set_axis_title_labels(ax2, title='MNIST - PCA - Choosing k with the Variance method',\n",
    "                                        x_label='Number of components k', y_label='Cumulative Variance (%)')\n",
    "\n",
    "        # Save figure\n",
    "        utils.save_figure_tight('{}_pca_model_complexity'.format(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## DR experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def dimensionality_reduction(x_train, x_test, y_train, **kwargs):\n",
    "    print('\\n--------------------------')\n",
    "    print('PCA')\n",
    "    print('--------------------------')\n",
    "\n",
    "    # Declare PCA, perform experiments by reducing the dataset and perform clustering experiments on it\n",
    "    pca = PrincipalComponents(n_components=kwargs['pca_n_components'])\n",
    "    x_pca = pca.experiment(x_train, x_test, y_train,\n",
    "                           dataset=kwargs['dataset'],\n",
    "                           perform_model_complexity=kwargs['perform_model_complexity'])\n",
    "\n",
    "    clustering(x_pca[0],  x_pca[1], y_train,\n",
    "               dataset=kwargs['dataset'] + '_pca_reduced',\n",
    "               kmeans_n_clusters=kwargs['pca_kmeans_n_clusters'],\n",
    "               em_n_clusters=kwargs['pca_em_n_clusters'], em_covariance=kwargs['pca_em_covariance'],\n",
    "               perform_model_complexity=kwargs['perform_model_complexity'])\n",
    "\n",
    "    print('\\n--------------------------')\n",
    "    print('ICA')\n",
    "    print('--------------------------')\n",
    "\n",
    "    # # Declare ICA, perform experiments by reducing the dataset and perform clustering experiments on it\n",
    "    ica = IndependentComponents(n_components=kwargs['ica_n_components'])\n",
    "    x_ica = ica.experiment(x_train, x_test, y_train,\n",
    "                           dataset=kwargs['dataset'],\n",
    "                           perform_model_complexity=kwargs['perform_model_complexity'])\n",
    "\n",
    "    clustering(x_ica[0],  x_ica[1], y_train,\n",
    "               dataset=kwargs['dataset'] + '_ica_reduced',\n",
    "               kmeans_n_clusters=kwargs['ica_kmeans_n_clusters'],\n",
    "               em_n_clusters=kwargs['ica_em_n_clusters'], em_covariance=kwargs['ica_em_covariance'],\n",
    "               perform_model_complexity=kwargs['perform_model_complexity'])\n",
    "\n",
    "\n",
    "    print('\\n--------------------------')\n",
    "    print('RP')\n",
    "    print('--------------------------')\n",
    "\n",
    "    # # Declare RP, perform experiments by reducing the dataset and perform clustering experiments on it\n",
    "    rp = RandomProjections(n_components=kwargs['rp_n_components'])\n",
    "    x_rp = rp.experiment(x_train, x_test, y_train,\n",
    "                         dataset=kwargs['dataset'],\n",
    "                         perform_model_complexity=kwargs['perform_model_complexity'])\n",
    "\n",
    "    clustering(x_rp[0], x_rp[1], y_train,\n",
    "               dataset=kwargs['dataset'] + '_rp_reduced',\n",
    "               kmeans_n_clusters=kwargs['rp_kmeans_n_clusters'],\n",
    "               em_n_clusters=kwargs['rp_em_n_clusters'], em_covariance=kwargs['rp_em_covariance'],\n",
    "               perform_model_complexity=kwargs['perform_model_complexity'])\n",
    "\n",
    "    print('\\n--------------------------')\n",
    "    print('KPCA')\n",
    "    print('--------------------------')\n",
    "\n",
    "    # Declare KPCA, perform experiments by reducing the dataset and perform clustering experiments on it\n",
    "    kpca = KernelPrincipalComponents(n_components=kwargs['kpca_n_components'], kernel=kwargs['kpca_kernel'])\n",
    "    x_kpca = kpca.experiment(x_train, x_test, y_train,\n",
    "                             dataset=kwargs['dataset'],\n",
    "                             perform_model_complexity=kwargs['perform_model_complexity'])\n",
    "\n",
    "    clustering(x_kpca[0], x_kpca[1], y_train,\n",
    "               dataset=kwargs['dataset'] + '_kpca_reduced',\n",
    "               kmeans_n_clusters=kwargs['kpca_kmeans_n_clusters'],\n",
    "               em_n_clusters=kwargs['kpca_em_n_clusters'], em_covariance=kwargs['kpca_em_covariance'],\n",
    "               perform_model_complexity=kwargs['perform_model_complexity'])\n",
    "\n",
    "    print('\\n--------------------------')\n",
    "    print('LDA')\n",
    "    print('--------------------------')\n",
    "\n",
    "    # # Declare RP, perform experiments by reducing the dataset and perform clustering experiments on it\n",
    "    # lda = LinearDiscriminantAnalysis(n_components=kwargs['rp_n_components'])\n",
    "    # x_lda = lda.experiment(x_train, x_test, y_train,\n",
    "    #                      dataset=kwargs['dataset'],\n",
    "    #                      perform_model_complexity=kwargs['perform_model_complexity'])\n",
    "    #\n",
    "    # clustering(x_lda[0], x_lda[1], y_train,\n",
    "    #            dataset=kwargs['dataset'] + '_rp_reduced',\n",
    "    #            kmeans_n_clusters=kwargs['lda_kmeans_n_clusters'],\n",
    "    #            em_n_clusters=kwargs['lda_em_n_clusters'], em_covariance=kwargs['lda_em_covariance'],\n",
    "    #            perform_model_complexity=kwargs['perform_model_complexity'])\n",
    "\n",
    "    return x_pca, x_ica, x_kpca, x_rp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------\n",
      "PCA\n",
      "--------------------------\n",
      "\n",
      "Train on training set\n",
      "\n",
      "Plot Model Complexity\n",
      "Explained variance [n components = 260]= 0.947\n",
      "Reconstruction error = 0.045\n",
      "Reduced dimension:  (5600, 260)\n",
      "\n",
      "--------------------------\n",
      "kMeans\n",
      "\n",
      "Plot Model Complexity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1 -->  inertia = 3526216.864  silhouette = 0.000 homogeneity = 0.000 completeness = 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 2 -->  inertia = 3373636.537  silhouette = 0.087 homogeneity = 0.130 completeness = 0.323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 5 -->  inertia = 3126760.810  silhouette = 0.273 homogeneity = 0.010 completeness = 0.414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 8 -->  inertia = 2971977.953  silhouette = 0.383 homogeneity = 0.003 completeness = 0.445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 10 -->  inertia = 2897464.099  silhouette = 0.431 homogeneity = 0.006 completeness = 0.451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 12 -->  inertia = 2833702.693  silhouette = 0.459 homogeneity = 0.014 completeness = 0.459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 15 -->  inertia = 2755281.731  silhouette = 0.497 homogeneity = 0.022 completeness = 0.457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-794a9eb99792>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'MNIST'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mperform_model_complexity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m x_pca, x_ica, x_kpca, x_rp = dimensionality_reduction(x_train, x_test, y_train,\n\u001b[0m\u001b[1;32m      4\u001b[0m                                                               \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                               \u001b[0mpca_n_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m260\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpca_kmeans_n_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-d4f31f32f82c>\u001b[0m in \u001b[0;36mdimensionality_reduction\u001b[0;34m(x_train, x_test, y_train, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m                            perform_model_complexity=kwargs['perform_model_complexity'])\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     clustering(x_pca[0],  x_pca[1], y_train,\n\u001b[0m\u001b[1;32m     13\u001b[0m                \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_pca_reduced'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                \u001b[0mkmeans_n_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pca_kmeans_n_clusters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-908c992ec44f>\u001b[0m in \u001b[0;36mclustering\u001b[0;34m(x_train, x_test, y_train, **kwargs)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# # Declare kMeans, perform experiments and get clusters on training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mkmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeansClustering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'kmeans_n_clusters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_n_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     kmeans_clusters = kmeans.experiment(x_train, x_test, y_train,\n\u001b[0m\u001b[1;32m      8\u001b[0m                                         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                         perform_model_complexity=kwargs['perform_model_complexity'])\n",
      "\u001b[0;32m<ipython-input-2-a37c7f593ac2>\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(self, x_train, x_test, y_train, dataset, perform_model_complexity)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mperform_model_complexity\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_model_complexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# fit the model and benchmark on training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-7f95524bd16d>\u001b[0m in \u001b[0;36mplot_model_complexity\u001b[0;34m(self, x, y, dataset)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mh_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhomogeneity_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                 \u001b[0ms_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msilhouette_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'euclidean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0ms_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/cluster/_unsupervised.py\u001b[0m in \u001b[0;36msilhouette_score\u001b[0;34m(X, labels, metric, sample_size, random_state, **kwds)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msilhouette_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/cluster/_unsupervised.py\u001b[0m in \u001b[0;36msilhouette_samples\u001b[0;34m(X, labels, metric, **kwds)\u001b[0m\n\u001b[1;32m    232\u001b[0m     reduce_func = functools.partial(_silhouette_reduce,\n\u001b[1;32m    233\u001b[0m                                     labels=labels, label_freqs=label_freqs)\n\u001b[0;32m--> 234\u001b[0;31m     results = zip(*pairwise_distances_chunked(X, reduce_func=reduce_func,\n\u001b[0m\u001b[1;32m    235\u001b[0m                                               **kwds))\n\u001b[1;32m    236\u001b[0m     \u001b[0mintra_clust_dists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minter_clust_dists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   1624\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreduce_func\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1625\u001b[0m             \u001b[0mchunk_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD_chunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1626\u001b[0;31m             \u001b[0mD_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1627\u001b[0m             \u001b[0m_check_chunk_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mD_chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/cluster/_unsupervised.py\u001b[0m in \u001b[0;36m_silhouette_reduce\u001b[0;34m(D_chunk, start, labels, label_freqs)\u001b[0m\n\u001b[1;32m    136\u001b[0m                            dtype=D_chunk.dtype)\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_chunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         clust_dists[i] += np.bincount(labels, weights=D_chunk[i],\n\u001b[0m\u001b[1;32m    139\u001b[0m                                       minlength=len(label_freqs))\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mbincount\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = 'MNIST'\n",
    "perform_model_complexity = True\n",
    "x_pca, x_ica, x_kpca, x_rp = dimensionality_reduction(x_train, x_test, y_train,\n",
    "                                                              dataset=dataset,\n",
    "                                                              pca_n_components=260, pca_kmeans_n_clusters=2,\n",
    "                                                              pca_em_n_clusters=6, pca_em_covariance='full',\n",
    "                                                              ica_n_components=320, ica_kmeans_n_clusters=2,\n",
    "                                                              ica_em_n_clusters=10, ica_em_covariance='diag',\n",
    "                                                              kpca_n_components=260, kpca_kernel='cosine',\n",
    "                                                              kpca_kmeans_n_clusters=2,\n",
    "                                                              kpca_em_n_clusters=3, kpca_em_covariance='full',\n",
    "                                                              rp_n_components=500, rp_kmeans_n_clusters=2,\n",
    "                                                              rp_em_n_clusters=2, rp_em_covariance='tied',\n",
    "                                                              lda_n_components=10, lda_kmeans_n_clusters=2,\n",
    "                                                              lda_em_n_clusters=5, lda_em_covariance='diag',\n",
    "                                                              perform_model_complexity=perform_model_complexity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------\n",
      "PCA\n",
      "--------------------------\n",
      "\n",
      "Train on training set\n",
      "\n",
      "Plot Model Complexity\n",
      "Explained variance [n components = 260]= 0.947\n",
      "Reconstruction error = 0.045\n",
      "Reduced dimension:  (5600, 260)\n",
      "\n",
      "--------------------------\n",
      "kMeans\n",
      "\n",
      "Plot Model Complexity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 2 -->  inertia = 3373636.537  silhouette = 0.087 homogeneity = 0.130 completeness = 0.323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 3 -->  inertia = 3276418.870  silhouette = 0.222 homogeneity = 0.055 completeness = 0.516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 4 -->  inertia = 3194948.220  silhouette = 0.246 homogeneity = 0.044 completeness = 0.433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 5 -->  inertia = 3126760.810  silhouette = 0.273 homogeneity = 0.010 completeness = 0.414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 6 -->  inertia = 3070077.424  silhouette = 0.306 homogeneity = 0.007 completeness = 0.413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 7 -->  inertia = 3016596.868  silhouette = 0.360 homogeneity = -0.004 completeness = 0.445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 8 -->  inertia = 2971977.953  silhouette = 0.383 homogeneity = 0.003 completeness = 0.445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 9 -->  inertia = 2932845.005  silhouette = 0.400 homogeneity = 0.005 completeness = 0.440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 10 -->  inertia = 2897464.099  silhouette = 0.431 homogeneity = 0.006 completeness = 0.451\n",
      "\n",
      "Train on training set with k=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "0.087\t0.323\t0.137\t0.057\t0.137\t0.130\n",
      "\n",
      "Benchmark Model with k = n classes = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "0.431\t0.451\t0.441\t0.319\t0.439\t0.006\n",
      "\n",
      "--------------------------\n",
      "GMM\n",
      "\n",
      "Plot Model Complexity\n",
      "cv = diag, k = 2 --> aic = 3962829.379, bic = 3969731.752\n",
      "cv_type = diag, k = 2 --> homogeneity = 0.018, completeness = 0.097\n",
      "cv = diag, k = 3 --> aic = 3849786.315, bic = 3860143.190\n",
      "cv_type = diag, k = 3 --> homogeneity = 0.048, completeness = 0.126\n",
      "cv = diag, k = 4 --> aic = 3788040.952, bic = 3801852.329\n",
      "cv_type = diag, k = 4 --> homogeneity = 0.135, completeness = 0.293\n",
      "cv = diag, k = 5 --> aic = 3754490.522, bic = 3771756.401\n",
      "cv_type = diag, k = 5 --> homogeneity = 0.136, completeness = 0.240\n",
      "cv = diag, k = 6 --> aic = 3740555.724, bic = 3761276.105\n",
      "cv_type = diag, k = 6 --> homogeneity = 0.137, completeness = 0.206\n",
      "cv = diag, k = 7 --> aic = 3731227.492, bic = 3755402.375\n",
      "cv_type = diag, k = 7 --> homogeneity = 0.168, completeness = 0.237\n",
      "cv = diag, k = 8 --> aic = 3708948.089, bic = 3736577.474\n",
      "cv_type = diag, k = 8 --> homogeneity = 0.180, completeness = 0.247\n",
      "cv = diag, k = 9 --> aic = 3698641.199, bic = 3729725.085\n",
      "cv_type = diag, k = 9 --> homogeneity = 0.210, completeness = 0.269\n",
      "cv = diag, k = 10 --> aic = 3694145.222, bic = 3728683.610\n",
      "cv_type = diag, k = 10 --> homogeneity = 0.199, completeness = 0.250\n",
      "\n",
      "Train on training set with k=6\n",
      "homo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "0.058\t0.133\t0.081\t0.031\t0.078\t0.095\n",
      "\n",
      "Benchmark Model with k = n classes = 10\n",
      "homo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "0.088\t0.124\t0.103\t0.056\t0.099\t0.030\n",
      "\n",
      "--------------------------\n",
      "ICA\n",
      "--------------------------\n",
      "\n",
      "Train on training set\n",
      "\n",
      "Plot Model Complexity\n",
      "k = 1 --> average kurtosis = 3.464\n",
      "k = 20 --> average kurtosis = 8.852\n",
      "k = 40 --> average kurtosis = 17.932\n",
      "k = 60 --> average kurtosis = 31.726\n",
      "k = 80 --> average kurtosis = 38.962\n",
      "k = 100 --> average kurtosis = 64.716\n",
      "k = 120 --> average kurtosis = 77.663\n",
      "k = 140 --> average kurtosis = 77.813\n",
      "k = 160 --> average kurtosis = 88.796\n",
      "k = 180 --> average kurtosis = 97.477\n",
      "k = 200 --> average kurtosis = 112.580\n",
      "k = 220 --> average kurtosis = 116.326\n",
      "k = 240 --> average kurtosis = 110.027\n",
      "k = 260 --> average kurtosis = 106.500\n",
      "k = 280 --> average kurtosis = 123.961\n",
      "k = 300 --> average kurtosis = 121.144\n",
      "k = 320 --> average kurtosis = 106.771\n",
      "k = 340 --> average kurtosis = 125.580\n",
      "k = 360 --> average kurtosis = 127.485\n",
      "k = 380 --> average kurtosis = 117.936\n",
      "k = 400 --> average kurtosis = 147.827\n",
      "k = 420 --> average kurtosis = 130.931\n",
      "k = 440 --> average kurtosis = 140.603\n",
      "k = 460 --> average kurtosis = 140.438\n",
      "k = 480 --> average kurtosis = 137.149\n",
      "k = 500 --> average kurtosis = 157.692\n",
      "k = 520 --> average kurtosis = 148.337\n",
      "k = 540 --> average kurtosis = 164.080\n",
      "k = 560 --> average kurtosis = 166.704\n",
      "k = 580 --> average kurtosis = 150.950\n",
      "k = 600 --> average kurtosis = 180.999\n",
      "k = 620 --> average kurtosis = 180.266\n",
      "Reconstruction error = 0.028\n",
      "Reduced dimension:  (5600, 320)\n",
      "\n",
      "--------------------------\n",
      "kMeans\n",
      "\n",
      "Plot Model Complexity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 2 -->  inertia = 319.116  silhouette = 0.006 homogeneity = 0.262 completeness = 0.274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 3 -->  inertia = 318.159  silhouette = 0.016 homogeneity = -0.038 completeness = 0.104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 4 -->  inertia = 317.177  silhouette = 0.017 homogeneity = -0.036 completeness = 0.108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 5 -->  inertia = 316.322  silhouette = 0.029 homogeneity = -0.043 completeness = 0.152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 6 -->  inertia = 315.490  silhouette = 0.078 homogeneity = -0.054 completeness = 0.253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 7 -->  inertia = 314.681  silhouette = 0.076 homogeneity = -0.070 completeness = 0.236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 8 -->  inertia = 313.598  silhouette = 0.032 homogeneity = -0.086 completeness = 0.190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 9 -->  inertia = 312.747  silhouette = 0.081 homogeneity = -0.084 completeness = 0.249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 10 -->  inertia = 312.008  silhouette = 0.143 homogeneity = -0.140 completeness = 0.319\n",
      "\n",
      "Train on training set with k=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "0.006\t0.274\t0.011\t0.000\t0.010\t0.262\n",
      "\n",
      "Benchmark Model with k = n classes = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "0.143\t0.319\t0.198\t0.048\t0.195\t-0.140\n",
      "\n",
      "--------------------------\n",
      "GMM\n",
      "\n",
      "Plot Model Complexity\n",
      "cv = diag, k = 2 --> aic = -12507469.112, bic = -12498975.414\n",
      "cv_type = diag, k = 2 --> homogeneity = 0.022, completeness = 0.121\n",
      "cv = diag, k = 3 --> aic = -12885274.803, bic = -12872530.940\n",
      "cv_type = diag, k = 3 --> homogeneity = 0.083, completeness = 0.221\n",
      "cv = diag, k = 4 --> aic = -13086741.811, bic = -13069747.783\n",
      "cv_type = diag, k = 4 --> homogeneity = 0.103, completeness = 0.209\n",
      "cv = diag, k = 5 --> aic = -13268489.016, bic = -13247244.824\n",
      "cv_type = diag, k = 5 --> homogeneity = 0.132, completeness = 0.242\n",
      "cv = diag, k = 6 --> aic = -13361479.133, bic = -13335984.776\n",
      "cv_type = diag, k = 6 --> homogeneity = 0.138, completeness = 0.224\n",
      "cv = diag, k = 7 --> aic = -13466265.256, bic = -13436520.734\n",
      "cv_type = diag, k = 7 --> homogeneity = 0.175, completeness = 0.247\n",
      "cv = diag, k = 8 --> aic = -13535498.773, bic = -13501504.087\n",
      "cv_type = diag, k = 8 --> homogeneity = 0.203, completeness = 0.274\n",
      "cv = diag, k = 9 --> aic = -13597974.655, bic = -13559729.805\n",
      "cv_type = diag, k = 9 --> homogeneity = 0.224, completeness = 0.281\n",
      "cv = diag, k = 10 --> aic = -13627361.006, bic = -13584865.991\n",
      "cv_type = diag, k = 10 --> homogeneity = 0.234, completeness = 0.275\n",
      "\n",
      "Train on training set with k=10\n",
      "homo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "0.234\t0.275\t0.253\t0.154\t0.250\t-0.052\n",
      "\n",
      "Benchmark Model with k = n classes = 10\n",
      "homo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "0.234\t0.275\t0.253\t0.154\t0.250\t-0.052\n",
      "\n",
      "--------------------------\n",
      "RP\n",
      "--------------------------\n",
      "\n",
      "Train on training set\n",
      "\n",
      "Plot Model Complexity\n",
      "Random run 1\n",
      "Random run 2\n",
      "Random run 3\n",
      "Random run 4\n",
      "Random run 5\n",
      "Random run 6\n",
      "Random run 7\n",
      "Random run 8\n",
      "Random run 9\n",
      "Random run 10\n",
      "Random run 11\n",
      "Random run 12\n",
      "Random run 13\n",
      "Random run 14\n",
      "Random run 15\n",
      "Random run 16\n",
      "Random run 17\n",
      "Random run 18\n",
      "Random run 19\n",
      "Random run 20\n",
      "Random run 21\n",
      "Random run 22\n",
      "Random run 23\n",
      "Random run 24\n",
      "Random run 25\n",
      "Random run 26\n",
      "Random run 27\n",
      "Random run 28\n",
      "Random run 29\n",
      "Random run 30\n",
      "Random run 31\n",
      "Random run 32\n",
      "Random run 33\n",
      "Random run 34\n",
      "Random run 35\n",
      "Random run 36\n",
      "Random run 37\n",
      "Random run 38\n",
      "Random run 39\n",
      "Random run 40\n",
      "Random run 41\n",
      "Random run 42\n",
      "Random run 43\n",
      "Random run 44\n",
      "Random run 45\n",
      "Random run 46\n",
      "Random run 47\n",
      "Random run 48\n",
      "Random run 49\n",
      "Random run 50\n",
      "Random run 51\n",
      "Random run 52\n",
      "Random run 53\n",
      "Random run 54\n",
      "Random run 55\n",
      "Random run 56\n",
      "Random run 57\n",
      "Random run 58\n",
      "Random run 59\n",
      "Random run 60\n",
      "Random run 61\n",
      "Random run 62\n",
      "Random run 63\n",
      "Random run 64\n",
      "Random run 65\n",
      "Random run 66\n",
      "Random run 67\n",
      "Random run 68\n",
      "Random run 69\n",
      "Random run 70\n",
      "Random run 71\n",
      "Random run 72\n",
      "Random run 73\n",
      "Random run 74\n",
      "Random run 75\n",
      "Random run 76\n",
      "Random run 77\n",
      "Random run 78\n",
      "Random run 79\n",
      "Random run 80\n",
      "Random run 81\n",
      "Random run 82\n",
      "Random run 83\n",
      "Random run 84\n",
      "Random run 85\n",
      "Random run 86\n",
      "Random run 87\n",
      "Random run 88\n",
      "Random run 89\n",
      "Random run 90\n",
      "Random run 91\n",
      "Random run 92\n",
      "Random run 93\n",
      "Random run 94\n",
      "Random run 95\n",
      "Random run 96\n",
      "Random run 97\n",
      "Random run 98\n",
      "Random run 99\n",
      "Random run 100\n",
      "k = [2, ..., 700] --> \n",
      "Reconstruction errors = [0.85 0.83 0.81 0.78 0.76 0.74 0.72 0.7  0.68 0.65 0.63 0.61 0.59 0.57\n",
      " 0.55 0.52 0.5  0.48 0.46 0.44 0.41 0.39 0.37 0.35 0.33 0.31 0.29 0.26\n",
      " 0.24 0.22 0.2  0.18 0.16 0.13 0.11 0.09]\n",
      "Reconstruction error = 0.308 with std = 0.002\n",
      "\n",
      "--------------------------\n",
      "kMeans\n",
      "\n",
      "Plot Model Complexity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 2 -->  inertia = 35361.091  silhouette = 0.086 homogeneity = 0.128 completeness = 0.323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 3 -->  inertia = 34282.997  silhouette = 0.211 homogeneity = 0.051 completeness = 0.475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 4 -->  inertia = 33485.414  silhouette = 0.216 homogeneity = 0.031 completeness = 0.387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 5 -->  inertia = 32776.828  silhouette = 0.247 homogeneity = 0.013 completeness = 0.379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 6 -->  inertia = 32215.902  silhouette = 0.292 homogeneity = 0.010 completeness = 0.399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 7 -->  inertia = 31707.601  silhouette = 0.329 homogeneity = 0.005 completeness = 0.409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 8 -->  inertia = 31318.232  silhouette = 0.366 homogeneity = 0.002 completeness = 0.428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 9 -->  inertia = 30952.524  silhouette = 0.377 homogeneity = 0.003 completeness = 0.412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 10 -->  inertia = 30590.191  silhouette = 0.404 homogeneity = 0.001 completeness = 0.426\n",
      "\n",
      "Train on training set with k=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "0.086\t0.323\t0.136\t0.056\t0.135\t0.128\n",
      "\n",
      "Benchmark Model with k = n classes = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "0.404\t0.426\t0.415\t0.306\t0.413\t0.001\n",
      "\n",
      "--------------------------\n",
      "GMM\n",
      "\n",
      "Plot Model Complexity\n",
      "cv = diag, k = 2 --> aic = -4962588.363, bic = -4949320.688\n",
      "cv_type = diag, k = 2 --> homogeneity = 0.032, completeness = 0.126\n",
      "cv = diag, k = 3 --> aic = -5229115.525, bic = -5209210.699\n",
      "cv_type = diag, k = 3 --> homogeneity = 0.069, completeness = 0.174\n",
      "cv = diag, k = 4 --> aic = -5422019.403, bic = -5395477.424\n",
      "cv_type = diag, k = 4 --> homogeneity = 0.147, completeness = 0.301\n",
      "cv = diag, k = 5 --> aic = -5540476.477, bic = -5507297.345\n",
      "cv_type = diag, k = 5 --> homogeneity = 0.250, completeness = 0.398\n",
      "cv = diag, k = 6 --> aic = -5610391.571, bic = -5570575.287\n",
      "cv_type = diag, k = 6 --> homogeneity = 0.265, completeness = 0.363\n",
      "cv = diag, k = 7 --> aic = -5669826.865, bic = -5623373.428\n",
      "cv_type = diag, k = 7 --> homogeneity = 0.311, completeness = 0.390\n",
      "cv = diag, k = 8 --> aic = -5728386.598, bic = -5675296.010\n",
      "cv_type = diag, k = 8 --> homogeneity = 0.323, completeness = 0.378\n",
      "cv = diag, k = 9 --> aic = -5784632.312, bic = -5724904.571\n",
      "cv_type = diag, k = 9 --> homogeneity = 0.370, completeness = 0.401\n",
      "cv = diag, k = 10 --> aic = -5834688.150, bic = -5768323.256\n",
      "cv_type = diag, k = 10 --> homogeneity = 0.381, completeness = 0.392\n",
      "\n",
      "Train on training set with k=2\n",
      "homo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "0.005\t0.017\t0.008\t0.005\t0.007\t0.003\n",
      "\n",
      "Benchmark Model with k = n classes = 10\n",
      "homo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "0.012\t0.012\t0.012\t0.004\t0.009\t-0.027\n",
      "\n",
      "--------------------------\n",
      "KPCA\n",
      "--------------------------\n",
      "\n",
      "Train on training set\n",
      "\n",
      "Plot Model Complexity\n",
      "Kernel = rbf - Explained variance [n components = 260]= 0.820\n",
      "Kernel = cosine - Explained variance [n components = 260]= 0.951\n",
      "Reconstruction error = 0.000\n",
      "Reduced dimension:  (5600, 260)\n",
      "\n",
      "--------------------------\n",
      "kMeans\n",
      "\n",
      "Plot Model Complexity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 2 -->  inertia = 4979.156  silhouette = 0.080 homogeneity = 0.058 completeness = 0.319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 3 -->  inertia = 4734.948  silhouette = 0.243 homogeneity = 0.063 completeness = 0.557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 4 -->  inertia = 4581.937  silhouette = 0.302 homogeneity = 0.066 completeness = 0.520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 5 -->  inertia = 4451.387  silhouette = 0.364 homogeneity = 0.068 completeness = 0.541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 6 -->  inertia = 4335.007  silhouette = 0.408 homogeneity = 0.074 completeness = 0.531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 7 -->  inertia = 4234.822  silhouette = 0.431 homogeneity = 0.076 completeness = 0.514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 8 -->  inertia = 4151.742  silhouette = 0.430 homogeneity = 0.067 completeness = 0.491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 9 -->  inertia = 4075.401  silhouette = 0.426 homogeneity = 0.070 completeness = 0.455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 10 -->  inertia = 4014.340  silhouette = 0.477 homogeneity = 0.072 completeness = 0.484\n",
      "\n",
      "Train on training set with k=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "0.080\t0.319\t0.128\t0.049\t0.128\t0.058\n",
      "\n",
      "Benchmark Model with k = n classes = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:938: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(\"'n_jobs' was deprecated in version 0.23 and will be\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "0.477\t0.484\t0.480\t0.350\t0.479\t0.072\n",
      "\n",
      "--------------------------\n",
      "GMM\n",
      "\n",
      "Plot Model Complexity\n",
      "cv = diag, k = 2 --> aic = -5574459.158, bic = -5567556.785\n",
      "cv_type = diag, k = 2 --> homogeneity = 0.023, completeness = 0.099\n",
      "cv = diag, k = 3 --> aic = -5615765.926, bic = -5605409.051\n",
      "cv_type = diag, k = 3 --> homogeneity = 0.064, completeness = 0.158\n",
      "cv = diag, k = 4 --> aic = -5638399.889, bic = -5624588.512\n",
      "cv_type = diag, k = 4 --> homogeneity = 0.125, completeness = 0.254\n",
      "cv = diag, k = 5 --> aic = -5649311.319, bic = -5632045.440\n",
      "cv_type = diag, k = 5 --> homogeneity = 0.130, completeness = 0.231\n",
      "cv = diag, k = 6 --> aic = -5656965.126, bic = -5636244.745\n",
      "cv_type = diag, k = 6 --> homogeneity = 0.172, completeness = 0.270\n",
      "cv = diag, k = 7 --> aic = -5662788.587, bic = -5638613.704\n",
      "cv_type = diag, k = 7 --> homogeneity = 0.175, completeness = 0.243\n",
      "cv = diag, k = 8 --> aic = -5669060.904, bic = -5641431.519\n",
      "cv_type = diag, k = 8 --> homogeneity = 0.199, completeness = 0.275\n",
      "cv = diag, k = 9 --> aic = -5674606.817, bic = -5643522.930\n",
      "cv_type = diag, k = 9 --> homogeneity = 0.204, completeness = 0.283\n",
      "cv = diag, k = 10 --> aic = -5677554.538, bic = -5643016.149\n",
      "cv_type = diag, k = 10 --> homogeneity = 0.230, completeness = 0.296\n",
      "\n",
      "Train on training set with k=3\n",
      "homo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "0.093\t0.206\t0.128\t0.064\t0.127\t0.023\n",
      "\n",
      "Benchmark Model with k = n classes = 10\n",
      "homo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
      "0.129\t0.145\t0.137\t0.091\t0.134\t0.009\n",
      "\n",
      "--------------------------\n",
      "LDA\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "dataset = 'MADELON'\n",
    "perform_model_complexity = True\n",
    "x_pca, x_ica, x_kpca, x_rp = dimensionality_reduction(x_train, x_test, y_train,\n",
    "                                                              dataset=dataset,\n",
    "                                                              pca_n_components=260, pca_kmeans_n_clusters=2,\n",
    "                                                              pca_em_n_clusters=6, pca_em_covariance='full',\n",
    "                                                              ica_n_components=320, ica_kmeans_n_clusters=2,\n",
    "                                                              ica_em_n_clusters=10, ica_em_covariance='diag',\n",
    "                                                              kpca_n_components=260, kpca_kernel='cosine',\n",
    "                                                              kpca_kmeans_n_clusters=2,\n",
    "                                                              kpca_em_n_clusters=3, kpca_em_covariance='full',\n",
    "                                                              rp_n_components=500, rp_kmeans_n_clusters=2,\n",
    "                                                              rp_em_n_clusters=2, rp_em_covariance='tied',\n",
    "                                                              lda_n_components=10, lda_kmeans_n_clusters=2,\n",
    "                                                              lda_em_n_clusters=5, lda_em_covariance='diag',\n",
    "                                                              perform_model_complexity=perform_model_complexity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## NN with DR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Neural Network class\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "\n",
    "    def __init__(self, layer1_nodes, layer2_nodes, learning_rate):\n",
    "        self.model = MLPClassifier(hidden_layer_sizes=(layer1_nodes), activation='relu',\n",
    "                                   solver='sgd', alpha=0.01, batch_size=200, learning_rate='constant',\n",
    "                                   learning_rate_init=learning_rate, max_iter=1000, tol=1e-4,\n",
    "                                   early_stopping=False, validation_fraction=0.1, momentum=0.5,\n",
    "                                   n_iter_no_change=100, random_state=42)\n",
    "\n",
    "    def evaluate(self, x_test, y_test):\n",
    "\n",
    "        predictions = self.predict(x_test)  # predict on test data\n",
    "\n",
    "        print('\\nEvaluate on the Test Set')\n",
    "        print(classification_report(y_test, predictions))  # produce classification report\n",
    "        print('Confusion Matrix:')\n",
    "        print(confusion_matrix(y_test, predictions))  # produce confusion matrix\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "\n",
    "        # Fit the model and report training time\n",
    "        start_time = time.time()\n",
    "        self.model.fit(x_train, y_train)\n",
    "        end_time = time.time()\n",
    "\n",
    "        print('\\nFitting Training Set: {:.4f} seconds'.format(end_time-start_time))\n",
    "\n",
    "    def predict(self, x):\n",
    "\n",
    "        # Predict and report inference time\n",
    "        start_time = time.time()\n",
    "        predictions = self.model.predict(x)\n",
    "        end_time = time.time()\n",
    "\n",
    "        print('\\nPredicting on Testing Set: {:.4f} seconds'.format(end_time-start_time))\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def experiment(self, x_train, x_test, y_train, y_test):\n",
    "        self.fit(x_train, y_train)\n",
    "        self.evaluate(x_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## NN experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def neural_network(x_train, x_test, y_train, y_test,\n",
    "                   x_pca, x_ica, x_kpca, x_rp,\n",
    "                   x_kmeans, x_gmm, **kwargs):\n",
    "    \"\"\"Perform neural network experiment.\n",
    "\n",
    "        Args:\n",
    "           x_train (ndarray): training data.\n",
    "           x_test (ndarray): test data.\n",
    "           y_train (ndarray): training labels.\n",
    "           y_test (ndarray): test labels.\n",
    "           x_pca (ndarray): reduced dataset by PCA.\n",
    "           x_ica (ndarray): reduced dataset by ICA.\n",
    "           x_kpca (ndarray): reduced dataset by KPCA.\n",
    "           x_rp (ndarray): reduced dataset by RP.\n",
    "           x_kmeans (ndarray): clusters produced by k-Means.\n",
    "           x_gmm (ndarray): clusters produced by Gaussian Mixture Models.\n",
    "           kwargs (dict): additional arguments to pass:\n",
    "                    - layer1_nodes (int): number of neurons in first layer.\n",
    "                    - layer2_nodes (int): number of neurons in second layer.\n",
    "                    - learning_rate (float): learning rate.\n",
    "\n",
    "        Returns:\n",
    "           None.\n",
    "        \"\"\"\n",
    "\n",
    "    print('\\n--------------------------')\n",
    "    print('NN')\n",
    "    print('--------------------------')\n",
    "\n",
    "    # Declare Neural Network and perform experiments on the original dataset\n",
    "    nn = NeuralNetwork(layer1_nodes=kwargs['layer1_nodes'],\n",
    "                       layer2_nodes=kwargs['layer2_nodes'],\n",
    "                       learning_rate=kwargs['learning_rate'])\n",
    "    nn.experiment(x_train, x_test, y_train, y_test)\n",
    "\n",
    "    print('\\n--------------------------')\n",
    "    print('PCA + NN')\n",
    "    print('--------------------------')\n",
    "\n",
    "    # Declare Neural Network and perform experiments on the reduced dataset by PCA\n",
    "    nn = NeuralNetwork(layer1_nodes=kwargs['layer1_nodes'],\n",
    "                       layer2_nodes=kwargs['layer2_nodes'],\n",
    "                       learning_rate=kwargs['learning_rate'])\n",
    "    nn.experiment(x_pca[0], x_pca[1], y_train, y_test)\n",
    "\n",
    "    print('\\n--------------------------')\n",
    "    print('ICA + NN')\n",
    "    print('--------------------------')\n",
    "\n",
    "    # Declare Neural Network and perform experiments on the reduced dataset by ICA\n",
    "    nn = NeuralNetwork(layer1_nodes=kwargs['layer1_nodes'],\n",
    "                       layer2_nodes=kwargs['layer2_nodes'],\n",
    "                       learning_rate=kwargs['learning_rate'])\n",
    "    nn.experiment(x_ica[0], x_ica[1], y_train, y_test)\n",
    "\n",
    "    print('\\n--------------------------')\n",
    "    print('KPCA + NN')\n",
    "    print('--------------------------')\n",
    "\n",
    "    # Declare Neural Network and perform experiments on the reduced dataset by KPCA\n",
    "    nn = NeuralNetwork(layer1_nodes=kwargs['layer1_nodes'],\n",
    "                       layer2_nodes=kwargs['layer2_nodes'],\n",
    "                       learning_rate=kwargs['learning_rate'])\n",
    "    nn.experiment(x_kpca[0], x_kpca[1], y_train, y_test)\n",
    "\n",
    "    print('\\n--------------------------')\n",
    "    print('RP+ NN')\n",
    "    print('--------------------------')\n",
    "\n",
    "    # Declare Neural Network and perform experiments on the reduced dataset by RP\n",
    "    nn = NeuralNetwork(layer1_nodes=kwargs['layer1_nodes'],\n",
    "                       layer2_nodes=kwargs['layer2_nodes'],\n",
    "                       learning_rate=kwargs['learning_rate'])\n",
    "    nn.experiment(x_rp[0], x_rp[1], y_train, y_test)\n",
    "\n",
    "    print('\\n--------------------------')\n",
    "    print('KMEANS+ NN')\n",
    "    print('--------------------------')\n",
    "\n",
    "    # Declare Neural Network\n",
    "    nn = NeuralNetwork(layer1_nodes=kwargs['layer1_nodes'],\n",
    "                       layer2_nodes=kwargs['layer2_nodes'],\n",
    "                       learning_rate=kwargs['learning_rate'])\n",
    "\n",
    "    # Augment the original dataset by adding clusters produced by k-Means as features\n",
    "    x_kmeans_normalized = (x_kmeans[0] - np.mean(x_kmeans[0])) / np.std(x_kmeans[0])\n",
    "    x_kmeans_normalized = np.expand_dims(x_kmeans_normalized, axis=1)\n",
    "    x_train_new = np.append(x_train, x_kmeans_normalized, axis=1)\n",
    "    x_kmeans_normalized = (x_kmeans[1] - np.mean(x_kmeans[1])) / np.std(x_kmeans[1])\n",
    "    x_kmeans_normalized = np.expand_dims(x_kmeans_normalized, axis=1)\n",
    "    x_test_new = np.append(x_test, x_kmeans_normalized, axis=1)\n",
    "\n",
    "    # Perform experiments on it\n",
    "    nn.experiment(x_train_new, x_test_new, y_train, y_test)\n",
    "\n",
    "    print('\\n--------------------------')\n",
    "    print('GMM+ NN')\n",
    "    print('--------------------------')\n",
    "\n",
    "    # Declare Neural Network\n",
    "    nn = NeuralNetwork(layer1_nodes=kwargs['layer1_nodes'],\n",
    "                       layer2_nodes=kwargs['layer2_nodes'],\n",
    "                       learning_rate=kwargs['learning_rate'])\n",
    "\n",
    "    # Augment the original dataset by adding clusters produced by Gaussian Mixture Models as features\n",
    "    x_gmm_normalized = (x_gmm[0] - np.mean(x_gmm[0])) / np.std(x_gmm[0])\n",
    "    x_gmm_normalized = np.expand_dims(x_gmm_normalized, axis=1)\n",
    "    x_train_new = np.append(x_train, x_gmm_normalized, axis=1)\n",
    "    x_gmm_normalized = (x_gmm[1] - np.mean(x_gmm[1])) / np.std(x_gmm[1])\n",
    "    x_gmm_normalized = np.expand_dims(x_gmm_normalized, axis=1)\n",
    "    x_test_new = np.append(x_test, x_gmm_normalized, axis=1)\n",
    "\n",
    "    # Perform experiments on it\n",
    "    nn.experiment(x_train_new, x_test_new, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------\n",
      "NN\n",
      "--------------------------\n",
      "\n",
      "Fitting Training Set: 18.9585 seconds\n",
      "\n",
      "Predicting on Testing Set: 0.0061 seconds\n",
      "\n",
      "Evaluate on the Test Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       138\n",
      "           1       0.93      0.98      0.96       157\n",
      "           2       0.94      0.86      0.90       140\n",
      "           3       0.91      0.88      0.89       143\n",
      "           4       0.93      0.94      0.93       136\n",
      "           5       0.94      0.92      0.93       126\n",
      "           6       0.92      0.96      0.94       138\n",
      "           7       0.92      0.92      0.92       146\n",
      "           8       0.90      0.93      0.91       137\n",
      "           9       0.91      0.90      0.91       139\n",
      "\n",
      "    accuracy                           0.93      1400\n",
      "   macro avg       0.93      0.93      0.93      1400\n",
      "weighted avg       0.93      0.93      0.93      1400\n",
      "\n",
      "Confusion Matrix:\n",
      "[[136   0   1   0   0   0   1   0   0   0]\n",
      " [  0 154   0   1   0   0   0   0   2   0]\n",
      " [  0   0 120   3   2   0   3   5   6   1]\n",
      " [  1   4   2 126   1   4   3   0   1   1]\n",
      " [  1   0   0   0 128   0   3   1   1   2]\n",
      " [  1   0   1   3   0 116   1   1   2   1]\n",
      " [  0   1   2   0   0   0 132   1   2   0]\n",
      " [  0   1   0   2   3   0   0 135   0   5]\n",
      " [  0   4   0   1   0   2   0   1 127   2]\n",
      " [  0   1   1   3   4   2   0   3   0 125]]\n",
      "\n",
      "--------------------------\n",
      "PCA + NN\n",
      "--------------------------\n",
      "\n",
      "Fitting Training Set: 12.0663 seconds\n",
      "\n",
      "Predicting on Testing Set: 0.0037 seconds\n",
      "\n",
      "Evaluate on the Test Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       138\n",
      "           1       0.94      0.98      0.96       157\n",
      "           2       0.93      0.89      0.91       140\n",
      "           3       0.93      0.88      0.90       143\n",
      "           4       0.93      0.93      0.93       136\n",
      "           5       0.92      0.94      0.93       126\n",
      "           6       0.92      0.96      0.94       138\n",
      "           7       0.95      0.92      0.94       146\n",
      "           8       0.90      0.92      0.91       137\n",
      "           9       0.91      0.89      0.90       139\n",
      "\n",
      "    accuracy                           0.93      1400\n",
      "   macro avg       0.93      0.93      0.93      1400\n",
      "weighted avg       0.93      0.93      0.93      1400\n",
      "\n",
      "Confusion Matrix:\n",
      "[[136   0   1   0   1   0   0   0   0   0]\n",
      " [  0 154   0   0   0   0   0   1   2   0]\n",
      " [  0   0 124   1   2   0   3   3   6   1]\n",
      " [  0   3   3 126   1   4   3   0   1   2]\n",
      " [  1   0   0   0 127   0   4   1   1   2]\n",
      " [  1   0   0   3   0 118   1   0   3   0]\n",
      " [  0   1   2   0   1   0 133   0   0   1]\n",
      " [  1   1   1   1   1   0   0 135   0   6]\n",
      " [  0   3   1   2   0   4   0   0 126   1]\n",
      " [  1   1   1   3   4   2   0   2   1 124]]\n",
      "\n",
      "--------------------------\n",
      "ICA + NN\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting Training Set: 72.8614 seconds\n",
      "\n",
      "Predicting on Testing Set: 0.0032 seconds\n",
      "\n",
      "Evaluate on the Test Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96       138\n",
      "           1       0.89      0.98      0.93       157\n",
      "           2       0.91      0.83      0.87       140\n",
      "           3       0.90      0.84      0.87       143\n",
      "           4       0.86      0.91      0.89       136\n",
      "           5       0.83      0.87      0.84       126\n",
      "           6       0.89      0.91      0.90       138\n",
      "           7       0.95      0.87      0.91       146\n",
      "           8       0.89      0.85      0.87       137\n",
      "           9       0.87      0.88      0.87       139\n",
      "\n",
      "    accuracy                           0.89      1400\n",
      "   macro avg       0.89      0.89      0.89      1400\n",
      "weighted avg       0.89      0.89      0.89      1400\n",
      "\n",
      "Confusion Matrix:\n",
      "[[136   0   0   0   0   0   1   0   0   1]\n",
      " [  0 154   0   0   1   0   0   0   2   0]\n",
      " [  1   2 116   5   3   1   4   4   3   1]\n",
      " [  0   3   5 120   2   9   2   0   1   1]\n",
      " [  0   1   1   0 124   0   5   0   1   4]\n",
      " [  3   1   1   2   0 109   2   1   5   2]\n",
      " [  2   1   1   0   0   5 126   0   2   1]\n",
      " [  1   3   1   2   5   0   0 127   0   7]\n",
      " [  0   7   1   3   1   6   1   0 116   2]\n",
      " [  1   1   1   2   8   2   0   2   0 122]]\n",
      "\n",
      "--------------------------\n",
      "KPCA + NN\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanym/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting Training Set: 71.2502 seconds\n",
      "\n",
      "Predicting on Testing Set: 0.0032 seconds\n",
      "\n",
      "Evaluate on the Test Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       138\n",
      "           1       0.96      0.97      0.97       157\n",
      "           2       0.91      0.88      0.89       140\n",
      "           3       0.91      0.88      0.90       143\n",
      "           4       0.91      0.92      0.92       136\n",
      "           5       0.90      0.90      0.90       126\n",
      "           6       0.92      0.94      0.93       138\n",
      "           7       0.94      0.92      0.93       146\n",
      "           8       0.88      0.93      0.90       137\n",
      "           9       0.91      0.89      0.90       139\n",
      "\n",
      "    accuracy                           0.92      1400\n",
      "   macro avg       0.92      0.92      0.92      1400\n",
      "weighted avg       0.92      0.92      0.92      1400\n",
      "\n",
      "Confusion Matrix:\n",
      "[[135   0   1   0   1   0   1   0   0   0]\n",
      " [  0 153   0   1   0   0   0   1   2   0]\n",
      " [  0   0 123   2   2   1   2   4   5   1]\n",
      " [  0   1   4 126   1   7   1   1   1   1]\n",
      " [  0   0   1   0 125   0   4   1   1   4]\n",
      " [  1   0   1   3   0 114   3   0   4   0]\n",
      " [  0   1   3   0   0   0 130   0   4   0]\n",
      " [  1   1   0   2   2   0   1 135   0   4]\n",
      " [  0   3   1   1   0   2   0   0 127   3]\n",
      " [  0   1   1   3   6   2   0   2   0 124]]\n",
      "\n",
      "--------------------------\n",
      "RP+ NN\n",
      "--------------------------\n",
      "\n",
      "Fitting Training Set: 47.9843 seconds\n",
      "\n",
      "Predicting on Testing Set: 0.0042 seconds\n",
      "\n",
      "Evaluate on the Test Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       138\n",
      "           1       0.95      0.98      0.97       157\n",
      "           2       0.91      0.89      0.90       140\n",
      "           3       0.90      0.86      0.88       143\n",
      "           4       0.93      0.92      0.92       136\n",
      "           5       0.91      0.90      0.90       126\n",
      "           6       0.90      0.94      0.92       138\n",
      "           7       0.94      0.91      0.93       146\n",
      "           8       0.89      0.91      0.90       137\n",
      "           9       0.89      0.89      0.89       139\n",
      "\n",
      "    accuracy                           0.92      1400\n",
      "   macro avg       0.92      0.92      0.92      1400\n",
      "weighted avg       0.92      0.92      0.92      1400\n",
      "\n",
      "Confusion Matrix:\n",
      "[[136   0   2   0   0   0   0   0   0   0]\n",
      " [  0 154   0   1   0   0   0   1   1   0]\n",
      " [  0   0 124   3   2   0   3   3   5   0]\n",
      " [  0   1   6 123   1   7   3   0   1   1]\n",
      " [  1   0   0   0 125   0   5   2   1   2]\n",
      " [  1   0   1   2   0 113   3   0   4   2]\n",
      " [  0   2   2   0   0   0 130   1   1   2]\n",
      " [  3   1   0   1   2   0   0 133   1   5]\n",
      " [  0   3   1   3   0   2   1   0 124   3]\n",
      " [  2   1   0   3   5   2   0   1   1 124]]\n",
      "\n",
      "--------------------------\n",
      "KMEANS+ NN\n",
      "--------------------------\n",
      "\n",
      "Fitting Training Set: 19.7561 seconds\n",
      "\n",
      "Predicting on Testing Set: 0.0056 seconds\n",
      "\n",
      "Evaluate on the Test Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       138\n",
      "           1       0.94      0.99      0.96       157\n",
      "           2       0.91      0.87      0.89       140\n",
      "           3       0.92      0.88      0.90       143\n",
      "           4       0.91      0.93      0.92       136\n",
      "           5       0.94      0.92      0.93       126\n",
      "           6       0.92      0.95      0.93       138\n",
      "           7       0.94      0.92      0.93       146\n",
      "           8       0.90      0.92      0.91       137\n",
      "           9       0.90      0.88      0.89       139\n",
      "\n",
      "    accuracy                           0.93      1400\n",
      "   macro avg       0.93      0.93      0.93      1400\n",
      "weighted avg       0.93      0.93      0.93      1400\n",
      "\n",
      "Confusion Matrix:\n",
      "[[135   0   2   0   1   0   0   0   0   0]\n",
      " [  0 155   0   0   0   0   0   0   2   0]\n",
      " [  0   0 122   2   2   0   4   3   6   1]\n",
      " [  1   2   3 126   1   3   3   1   2   1]\n",
      " [  2   0   1   0 127   0   4   0   1   1]\n",
      " [  1   1   0   3   0 116   1   1   2   1]\n",
      " [  0   1   4   0   0   0 131   0   1   1]\n",
      " [  0   2   0   1   2   0   0 135   0   6]\n",
      " [  0   4   1   2   0   2   0   0 126   2]\n",
      " [  0   0   1   3   6   2   0   4   0 123]]\n",
      "\n",
      "--------------------------\n",
      "GMM+ NN\n",
      "--------------------------\n",
      "\n",
      "Fitting Training Set: 19.1407 seconds\n",
      "\n",
      "Predicting on Testing Set: 0.0053 seconds\n",
      "\n",
      "Evaluate on the Test Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       138\n",
      "           1       0.93      0.99      0.96       157\n",
      "           2       0.90      0.87      0.88       140\n",
      "           3       0.92      0.87      0.90       143\n",
      "           4       0.92      0.93      0.93       136\n",
      "           5       0.95      0.92      0.94       126\n",
      "           6       0.92      0.95      0.93       138\n",
      "           7       0.94      0.92      0.93       146\n",
      "           8       0.90      0.92      0.91       137\n",
      "           9       0.91      0.89      0.90       139\n",
      "\n",
      "    accuracy                           0.93      1400\n",
      "   macro avg       0.93      0.93      0.93      1400\n",
      "weighted avg       0.93      0.93      0.93      1400\n",
      "\n",
      "Confusion Matrix:\n",
      "[[136   0   1   0   1   0   0   0   0   0]\n",
      " [  0 155   0   0   0   0   0   0   2   0]\n",
      " [  0   0 122   3   2   0   4   3   5   1]\n",
      " [  1   3   4 125   1   3   3   0   2   1]\n",
      " [  1   0   2   0 127   0   4   0   1   1]\n",
      " [  1   1   0   3   0 116   1   1   2   1]\n",
      " [  0   1   4   0   0   0 131   0   1   1]\n",
      " [  0   2   0   1   2   0   0 135   0   6]\n",
      " [  0   4   2   1   0   2   0   0 126   2]\n",
      " [  0   0   1   3   5   1   0   4   1 124]]\n"
     ]
    }
   ],
   "source": [
    " neural_network(x_train, x_test, y_train, y_test,\n",
    "                       x_pca, x_ica, x_kpca, x_rp,\n",
    "                       kmeans_clusters, gmm_clusters,\n",
    "                       layer1_nodes=150, layer2_nodes=100, learning_rate=0.06)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (assignment1)",
   "language": "python",
   "name": "pycharm-9b15215"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
